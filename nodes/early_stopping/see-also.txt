* Other strategies for controlling overfitting in feed-forward neural nets include:
** "Weight decay":weight_decay_neural_networks, a form of $L_2$ regularization
** "Tikhonov regularization":tikhonov_regularization, which rewards invariance to noise in the inputs
** "Tangent propagation":tangent_propagation, which rewards invariance to irrelevant transformations of the inputs such as translation and scalling
** "Generative pre-training":generative_pre_training, which improves generalization by encouraging solutions which also reflect the data distribution
