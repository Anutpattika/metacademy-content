* Linear regression is a model for predicting real-valued targets. Other kinds of targets include:
** "binary":binary_classification
** "categorical":multiway_classification
** "ordinal":ordinal_regression (i.e. only the ordering of the values is significant)
* Vanilla linear regression is prone to "overfitting":generalization.
* Some extensions which deal with overfitting include:
** "ridge regression":ridge_regression
** "L1-regularized linear regression (Lasso)":lasso
** "PCA preprocessing":pca_preprocessing
** "Feature selection":feature_selection
** "Model selection":model_selection
* Vanilla linear regression is also sensitive to outliers. Some more robust alternatives include:
** "robust linear regression":robust_linear_regression
** "support vector regression":support_vector_regression
* The closed-form solution here does not scale well to large-scale problems (more than tens of thousands of variables). For these cases, look into "stochastic algorithms":stochastic_gradient_descent.
* Not all variables of interest can be modeled as linear functions of the input variables. To model nonlinear dependencies, check out:
** "basis function expansions":basis_function_expansions
** "neural networks":feed_forward_neural_nets
** "kernel methods":kernel_ridge_regression
* Linear regression "can be interpreted":linear_regression_as_maximum_likelihood as "maximum likelihood estimation":maximum_likelihood under a Gaussian noise model.
