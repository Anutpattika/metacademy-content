* Under widely held assumptions, there is "no efficient exact inference algorithm":complexity_of_inference for graphical models. 
* We can perform "inference in Bayes nets":inference_in_bayes_nets by converting them to MRFs. 
* Here are some algorithms for exact inference:
** "variable elimination":variable_elimination, a conceptually simple one
** belief propagation, an extension of variable elimination which reuses computations. This has two forms:
*** "sum-product":sum_product_on_trees, for computing marginals
*** "max-product":max_product_on_trees, for computing the most likely assignment
* When exact inference is infeasible, we must resort to approximate inference algorithms, such as:
** "loopy belief propagation":loopy_belief_propagation, which applies the BP update rules on non-tree graphs
** "Markov chain Monte Carlo":markov_chain_monte_carlo, a sampling-based method
** "variational inference":variational_inference, which tries to find a tractable approximation to the posterior
* "Inference is at most cubic in Gaussian graphical models":inference_in_gaussian_mrfs, and often much better


