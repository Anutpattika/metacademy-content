* Loopy BP is "guaranteed to converge":gaussian_loopy_bp to the correct mean for Gaussian graphical models.
* Loopy BP is "guaranteed to converge":loopy_bp_single_loop for  a graph with a single loop. 
* "Tree-reweighted belief propagation":tree_reweighted_belief_propagation is an algorithm inspired by the same ideas, but where the approximation to KL divergence is convex and gives an upper bound on the partition function. 
* Some other inference algorithms based on variational principles:
** "expectation propagation":expectation_propagation, which approximates BP messages in terms of expectations 
** "mean field approximation":mean_field_approximation, where different variables are approximated as independent in the posterior 
** "variational Bayes":variational_bayes, a general framework for posterior inference in Bayesian models 
