* For any parameter learning problem, we care how well the learned parameters can "generalize to new data":generalization.
* "Bayesian parameter estimation":bayesian_estimation_bayes_net_params is a way to avoid overfitting and incorporate prior knowledge.
* The "expectation-maximization (EM) algorithm":learning_bayes_nets_missing_data gives a way of dealing with missing entries.
* It's possible to "learn the structure itself":bayes_net_structure_learning, i.e. which edges should be included.
* We can "learn parameters for Markov random fields (MRFs)":mrf_parameter_learning using similar principles.
