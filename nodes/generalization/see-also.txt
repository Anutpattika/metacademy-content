* Some techniques for estimating generalization error include:
** Cross-validation, a simple and widely applicable technique [cross-validation]
** The Akaike information criterion (for probabilistic models) [akaike-information-criterion]
** The $C_p$ statistic (for linear regression) [cp-statistic]
* Here are some general strategies for controlling overfitting:
** model selection [model-selection]
** feature selection [feature-selection]
** regularization [regularization]
* Some theoretical concepts useful for understanding generalization include:
** For linear regression, generalization error can be determined analytically, and breaks down exactly into a sum of bias and variance terms. This provides a useful intuition for other models as well. [bias-variance-decomposition]
** Probably Approximately Correct (PAC) learning, which analyzes whether an algorithm usually learns a good-enough model [pac-learning]
** VC dimension, a quantity which characterizes the complexity of a continuously-parameterized model [vc-dimension]
** Structural risk minimization, a way of controlling overfitting by defining a nested sequence of models of increasing complexity [structural-risk-minimization]

